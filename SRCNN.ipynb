{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPptfGsYx2QChjfwSd0oqig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirbhayWorlikar/Deep-Learning/blob/main/SRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DD8qAIv_L4h",
        "outputId": "94f2d024-0770-4cc3-b809-0b0217b00545"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy import misc\n",
        "from scipy import ndimage\n",
        "import imageio\n",
        "from skimage import metrics\n",
        "from torchvision.utils import save_image\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imread(path, is_grayscale=True):\n",
        "    \"\"\"\n",
        "    Read image from the giving path.\n",
        "    Default value is gray-scale, and image is read by YCbCr format as the paper.\n",
        "    \"\"\"\n",
        "\n",
        "    if is_grayscale:\n",
        "\n",
        "        return imageio.imread(path, as_gray=True, pilmode='YCbCr').astype(np.float32)\n",
        "        #return misc.imread(path, flatten=True, mode='YCbCr').astype(np.float32)\n",
        "    else:\n",
        "        return imageio.imread(path, mode='YCbCr').astype(np.float32)\n",
        "        #return misc.imread(path, mode='YCbCr').astype(np.float32)\n",
        "\n",
        "\n",
        "def modcrop(image, scale=3):\n",
        "    \"\"\"\n",
        "    To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
        "\n",
        "    We need to find modulo of height (and width) and scale factor.\n",
        "    Then, subtract the modulo from height (and width) of original image size.\n",
        "    There would be no remainder even after scaling operation.\n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        h, w, _ = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w, :]\n",
        "    else:\n",
        "        h, w = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w]\n",
        "    return image\n",
        "\n",
        "\n",
        "def preprocess(path, scale=3):\n",
        "    \"\"\"\n",
        "    Preprocess single image file\n",
        "      (1) Read original image as YCbCr format (and grayscale as default)\n",
        "      (2) Normalize\n",
        "      (3) Apply image file with bicubic interpolation\n",
        "    Args:\n",
        "      path: file path of desired file\n",
        "      input_: image applied bicubic interpolation (low-resolution)\n",
        "      label_: image with original resolution (high-resolution)\n",
        "    \"\"\"\n",
        "    image = imread(path, is_grayscale=True)\n",
        "    label_ = modcrop(image, scale)\n",
        "\n",
        "    # Must be normalized\n",
        "    label_ = label_ / 255.\n",
        "\n",
        "    input_ = ndimage.interpolation.zoom(label_, (1. / scale), prefilter=False)\n",
        "    input_ = ndimage.interpolation.zoom(input_, (scale / 1.), prefilter=False)\n",
        "\n",
        "    return input_, label_\n",
        "\n",
        "\n",
        "\"\"\"Define the model weights and biases \n",
        "\"\"\"\n",
        "## ------ Add your code here: set the weight of three conv layers\n",
        "\n",
        "\n",
        "# replace 'None' with your hyper parameter numbers\n",
        "# conv1 layer with biases: 64 filters with size 9 x 9\n",
        "# conv2 layer with biases and relu: 32 filters with size 1 x 1\n",
        "# conv3 layer with biases and NO relu: 1 filter with size 5 x 5\n",
        "\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SRCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(9, 9), padding=4, bias=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(1, 1), padding=0, bias=True)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(5, 5), padding=2, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\"\"\"Load the pre-trained model file\n",
        "\"\"\"\n",
        "model = SRCNN()\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "model.eval()\n",
        "\n",
        "\"\"\"Read the test image\n",
        "\"\"\"\n",
        "LR_image, HR_image = preprocess('/content/butterfly_GT.bmp')\n",
        "# transform the input to 4-D tensor\n",
        "input_ = np.expand_dims(np.expand_dims(LR_image, axis=0), axis=0)\n",
        "input_ = torch.from_numpy(input_)\n",
        "\n",
        "\"\"\"Run the model and get the SR image\n",
        "\"\"\"\n",
        "with torch.no_grad():\n",
        "    output_ = model(input_)\n",
        "\n",
        "##------ Add your code here: save the LR and SR images and compute the psnr\n",
        "# hints: use the 'scipy.misc.imsave()'  and ' skimage.metrics.peak_signal_noise_ratio()'\n",
        "\n",
        "imageio.imwrite('HR.bmp', im=HR_image)\n",
        "imageio.imwrite('LR.bmp', im=LR_image)  \n",
        "save_image(output_, 'SR.bmp')\n",
        "\n",
        "psnr = metrics.peak_signal_noise_ratio(HR_image, LR_image)\n",
        "print(\"PSNR Value for HR and LR images is \", psnr)\n",
        "\n",
        "input = input_.detach().cpu().numpy()\n",
        "output = output_.detach().cpu().numpy()\n",
        "\n",
        "psnr = metrics.peak_signal_noise_ratio(output, input)\n",
        "print(\"PSNR Value for Input and Output images is \", psnr)\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR Value for HR and LR images is  20.497630181368823\n",
            "PSNR Value for Input and Output images is  27.959968736019732\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}